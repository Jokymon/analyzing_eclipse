{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ae43f",
   "metadata": {},
   "source": [
    "# Markov analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24676dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import matrix_power\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed09c6b",
   "metadata": {},
   "source": [
    "The following diagram shows all possible states of the Eclipse space battle with their corresponding transition probabilities.\n",
    "![](statespace.png)\n",
    "\n",
    "From this graph we can extract the following transition probability matrix. Each line represents the transition probabilities for one of the states. The first line for example contains the probabilities for state &#9312;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ca484",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities=np.array([[0, 4/9, 0, 4/9, 0, 1/9, 0], [5/6, 0, 1/6, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 5/6, 0, 1/6], [0, 0, 0, 4/9, 0, 5/9, 0], [0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1]])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd00f94",
   "metadata": {},
   "source": [
    "Now let's play around a little with these probabilities. The initial state of the game means, that the probability of being in state &#9312; is 100% or 1.0. So we define the ``initial_state`` like this and then see, what the probabilities are after two turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = np.array([1, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ce121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p2=np.dot(probabilities, probabilities)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(initial_state, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba561a",
   "metadata": {},
   "source": [
    "## Steady State?\n",
    "So do these values eventually reach a stable state - is there a so called steady state to this process? The easiest approach is to check if we are dealing with a regular Markov chain. But since already in the 0th iteration we have entries with a 0 in the transition matrix, we know, that is not the case.\n",
    "\n",
    "But with a sufficient amount of Markov steps we should reach a steady state. Let's try 1000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c98703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(initial_state, matrix_power(probabilities, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0296eb",
   "metadata": {},
   "source": [
    "How about after 2000 steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(initial_state, matrix_power(probabilities, 2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0e92b",
   "metadata": {},
   "source": [
    "The difference between the power of 1000 and 2000 aren't visible with 3 digits.\n",
    "\n",
    "So let's see, if this could be more efficient and let's determine an minimal amount of iterations needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = probabilities\n",
    "next = np.dot(initial_state, probabilities)\n",
    "power = 0\n",
    "while not np.allclose(prev, next):\n",
    "    power += 1\n",
    "    prev = next\n",
    "    next = np.dot(prev, probabilities)\n",
    "print(f\"Steady state after {power} iterations\")\n",
    "print(f\"Probabilities of states in steady state: \\n{prev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec8cfd",
   "metadata": {},
   "source": [
    "According to \"Markov Chain math\", it should also be possible to calculate the steady state by solving the equation $E\\vec{t}=\\vec{t}$, where $E$ is our transition probability matrix and $\\vec{t}$ will be the steady state vector. NumPy provides us with a way to solve equations of the form $A\\vec{x}=\\vec{b}$. But with a simple transformation we can get there as well. We can simply solve for $(E-I)\\vec{t}=0$ with $I$ being the identity matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
